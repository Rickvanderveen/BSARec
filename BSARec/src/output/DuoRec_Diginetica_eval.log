2025-06-14 21:47:07,935 - Namespace(data_dir='data/self_processed/', output_dir='output/', data_name='Diginetica', do_eval=True, load_model='DuoRec_Diginetica', train_name='Jun-14-2025_21-47-06', num_items=10, num_users=14829, lr=0.001, batch_size=256, epochs=200, no_cuda=False, log_freq=1, patience=10, num_workers=4, seed=42, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, gpu_id='0', variance=5, model_type='DuoRec', max_seq_length=50, hidden_size=64, num_hidden_layers=2, hidden_act='gelu', num_attention_heads=4, attention_probs_dropout_prob=0.5, hidden_dropout_prob=0.5, initializer_range=0.02, tau=1.0, lmd=0.1, lmd_sem=0.1, ssl='us_x', sim='dot', cuda_condition=True, data_file='data/self_processed/Diginetica.txt', item_size=9441, checkpoint_path='output/Jun-14-2025_21-47-06.pt', same_target_path='data/self_processed/Diginetica_same_target.npy')
2025-06-14 21:47:07,960 - DuoRecModel(
  (item_embeddings): Embedding(9441, 64, padding_idx=0)
  (position_embeddings): Embedding(50, 64)
  (LayerNorm): LayerNorm()
  (dropout): Dropout(p=0.5, inplace=False)
  (item_encoder): TransformerEncoder(
    (blocks): ModuleList(
      (0): TransformerBlock(
        (layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm()
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
      (1): TransformerBlock(
        (layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm()
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (aug_nce_fct): CrossEntropyLoss()
)
2025-06-14 21:47:10,140 - Total Parameters: 707520
2025-06-14 21:47:10,211 - odict_keys(['item_embeddings.weight', 'position_embeddings.weight', 'LayerNorm.weight', 'LayerNorm.bias', 'item_encoder.blocks.0.layer.query.weight', 'item_encoder.blocks.0.layer.query.bias', 'item_encoder.blocks.0.layer.key.weight', 'item_encoder.blocks.0.layer.key.bias', 'item_encoder.blocks.0.layer.value.weight', 'item_encoder.blocks.0.layer.value.bias', 'item_encoder.blocks.0.layer.dense.weight', 'item_encoder.blocks.0.layer.dense.bias', 'item_encoder.blocks.0.layer.LayerNorm.weight', 'item_encoder.blocks.0.layer.LayerNorm.bias', 'item_encoder.blocks.0.feed_forward.dense_1.weight', 'item_encoder.blocks.0.feed_forward.dense_1.bias', 'item_encoder.blocks.0.feed_forward.dense_2.weight', 'item_encoder.blocks.0.feed_forward.dense_2.bias', 'item_encoder.blocks.0.feed_forward.LayerNorm.weight', 'item_encoder.blocks.0.feed_forward.LayerNorm.bias', 'item_encoder.blocks.1.layer.query.weight', 'item_encoder.blocks.1.layer.query.bias', 'item_encoder.blocks.1.layer.key.weight', 'item_encoder.blocks.1.layer.key.bias', 'item_encoder.blocks.1.layer.value.weight', 'item_encoder.blocks.1.layer.value.bias', 'item_encoder.blocks.1.layer.dense.weight', 'item_encoder.blocks.1.layer.dense.bias', 'item_encoder.blocks.1.layer.LayerNorm.weight', 'item_encoder.blocks.1.layer.LayerNorm.bias', 'item_encoder.blocks.1.feed_forward.dense_1.weight', 'item_encoder.blocks.1.feed_forward.dense_1.bias', 'item_encoder.blocks.1.feed_forward.dense_2.weight', 'item_encoder.blocks.1.feed_forward.dense_2.bias', 'item_encoder.blocks.1.feed_forward.LayerNorm.weight', 'item_encoder.blocks.1.feed_forward.LayerNorm.bias'])
2025-06-14 21:47:10,218 - odict_keys(['item_embeddings.weight', 'position_embeddings.weight', 'LayerNorm.weight', 'LayerNorm.bias', 'item_encoder.blocks.0.layer.query.weight', 'item_encoder.blocks.0.layer.query.bias', 'item_encoder.blocks.0.layer.key.weight', 'item_encoder.blocks.0.layer.key.bias', 'item_encoder.blocks.0.layer.value.weight', 'item_encoder.blocks.0.layer.value.bias', 'item_encoder.blocks.0.layer.dense.weight', 'item_encoder.blocks.0.layer.dense.bias', 'item_encoder.blocks.0.layer.LayerNorm.weight', 'item_encoder.blocks.0.layer.LayerNorm.bias', 'item_encoder.blocks.0.feed_forward.dense_1.weight', 'item_encoder.blocks.0.feed_forward.dense_1.bias', 'item_encoder.blocks.0.feed_forward.dense_2.weight', 'item_encoder.blocks.0.feed_forward.dense_2.bias', 'item_encoder.blocks.0.feed_forward.LayerNorm.weight', 'item_encoder.blocks.0.feed_forward.LayerNorm.bias', 'item_encoder.blocks.1.layer.query.weight', 'item_encoder.blocks.1.layer.query.bias', 'item_encoder.blocks.1.layer.key.weight', 'item_encoder.blocks.1.layer.key.bias', 'item_encoder.blocks.1.layer.value.weight', 'item_encoder.blocks.1.layer.value.bias', 'item_encoder.blocks.1.layer.dense.weight', 'item_encoder.blocks.1.layer.dense.bias', 'item_encoder.blocks.1.layer.LayerNorm.weight', 'item_encoder.blocks.1.layer.LayerNorm.bias', 'item_encoder.blocks.1.feed_forward.dense_1.weight', 'item_encoder.blocks.1.feed_forward.dense_1.bias', 'item_encoder.blocks.1.feed_forward.dense_2.weight', 'item_encoder.blocks.1.feed_forward.dense_2.bias', 'item_encoder.blocks.1.feed_forward.LayerNorm.weight', 'item_encoder.blocks.1.feed_forward.LayerNorm.bias'])
2025-06-14 21:47:10,219 - Load model from output/DuoRec_Diginetica.pt for test!
2025-06-14 21:47:14,584 - {'Epoch': 0, 'HR@5': '0.1507', 'NDCG@5': '0.0987', 'HR@10': '0.2290', 'NDCG@10': '0.1239', 'HR@20': '0.3221', 'NDCG@20': '0.1474'}
2025-06-14 21:47:14,863 - Saved predictions in `output/predictions/DuoRec_Diginetica_predictions.csv`
2025-06-14 21:47:14,863 - Jun-14-2025_21-47-06
2025-06-14 21:47:14,863 - {'Epoch': 0, 'HR@5': '0.1507', 'NDCG@5': '0.0987', 'HR@10': '0.2290', 'NDCG@10': '0.1239', 'HR@20': '0.3221', 'NDCG@20': '0.1474'}
2025-06-23 12:56:18,847 - Namespace(data_dir='data/self_processed/', output_dir='output/', data_name='Diginetica', do_val_eval=False, do_eval=True, load_model='DuoRec_Diginetica', train_name='Jun-23-2025_12-56-17', num_items=10, num_users=14829, lr=0.001, batch_size=256, epochs=200, no_cuda=False, log_freq=1, patience=10, num_workers=4, seed=42, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, gpu_id='0', variance=5, model_type='DuoRec', max_seq_length=50, hidden_size=64, num_hidden_layers=2, hidden_act='gelu', num_attention_heads=4, attention_probs_dropout_prob=0.5, hidden_dropout_prob=0.5, initializer_range=0.02, tau=1.0, lmd=0.1, lmd_sem=0.1, ssl='us_x', sim='dot', cuda_condition=True, data_file='data/self_processed/Diginetica.txt', item_size=9441, checkpoint_path='output/Jun-23-2025_12-56-17.pt', same_target_path='data/self_processed/Diginetica_same_target.npy')
2025-06-23 12:56:18,877 - DuoRecModel(
  (item_embeddings): Embedding(9441, 64, padding_idx=0)
  (position_embeddings): Embedding(50, 64)
  (LayerNorm): LayerNorm()
  (dropout): Dropout(p=0.5, inplace=False)
  (item_encoder): TransformerEncoder(
    (blocks): ModuleList(
      (0): TransformerBlock(
        (layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm()
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
      (1): TransformerBlock(
        (layer): MultiHeadAttention(
          (query): Linear(in_features=64, out_features=64, bias=True)
          (key): Linear(in_features=64, out_features=64, bias=True)
          (value): Linear(in_features=64, out_features=64, bias=True)
          (softmax): Softmax(dim=-1)
          (attn_dropout): Dropout(p=0.5, inplace=False)
          (dense): Linear(in_features=64, out_features=64, bias=True)
          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)
          (out_dropout): Dropout(p=0.5, inplace=False)
        )
        (feed_forward): FeedForward(
          (dense_1): Linear(in_features=64, out_features=256, bias=True)
          (dense_2): Linear(in_features=256, out_features=64, bias=True)
          (LayerNorm): LayerNorm()
          (dropout): Dropout(p=0.5, inplace=False)
        )
      )
    )
  )
  (aug_nce_fct): CrossEntropyLoss()
)
2025-06-23 12:56:21,364 - Total Parameters: 707520
2025-06-23 12:56:21,439 - odict_keys(['item_embeddings.weight', 'position_embeddings.weight', 'LayerNorm.weight', 'LayerNorm.bias', 'item_encoder.blocks.0.layer.query.weight', 'item_encoder.blocks.0.layer.query.bias', 'item_encoder.blocks.0.layer.key.weight', 'item_encoder.blocks.0.layer.key.bias', 'item_encoder.blocks.0.layer.value.weight', 'item_encoder.blocks.0.layer.value.bias', 'item_encoder.blocks.0.layer.dense.weight', 'item_encoder.blocks.0.layer.dense.bias', 'item_encoder.blocks.0.layer.LayerNorm.weight', 'item_encoder.blocks.0.layer.LayerNorm.bias', 'item_encoder.blocks.0.feed_forward.dense_1.weight', 'item_encoder.blocks.0.feed_forward.dense_1.bias', 'item_encoder.blocks.0.feed_forward.dense_2.weight', 'item_encoder.blocks.0.feed_forward.dense_2.bias', 'item_encoder.blocks.0.feed_forward.LayerNorm.weight', 'item_encoder.blocks.0.feed_forward.LayerNorm.bias', 'item_encoder.blocks.1.layer.query.weight', 'item_encoder.blocks.1.layer.query.bias', 'item_encoder.blocks.1.layer.key.weight', 'item_encoder.blocks.1.layer.key.bias', 'item_encoder.blocks.1.layer.value.weight', 'item_encoder.blocks.1.layer.value.bias', 'item_encoder.blocks.1.layer.dense.weight', 'item_encoder.blocks.1.layer.dense.bias', 'item_encoder.blocks.1.layer.LayerNorm.weight', 'item_encoder.blocks.1.layer.LayerNorm.bias', 'item_encoder.blocks.1.feed_forward.dense_1.weight', 'item_encoder.blocks.1.feed_forward.dense_1.bias', 'item_encoder.blocks.1.feed_forward.dense_2.weight', 'item_encoder.blocks.1.feed_forward.dense_2.bias', 'item_encoder.blocks.1.feed_forward.LayerNorm.weight', 'item_encoder.blocks.1.feed_forward.LayerNorm.bias'])
2025-06-23 12:56:21,448 - odict_keys(['item_embeddings.weight', 'position_embeddings.weight', 'LayerNorm.weight', 'LayerNorm.bias', 'item_encoder.blocks.0.layer.query.weight', 'item_encoder.blocks.0.layer.query.bias', 'item_encoder.blocks.0.layer.key.weight', 'item_encoder.blocks.0.layer.key.bias', 'item_encoder.blocks.0.layer.value.weight', 'item_encoder.blocks.0.layer.value.bias', 'item_encoder.blocks.0.layer.dense.weight', 'item_encoder.blocks.0.layer.dense.bias', 'item_encoder.blocks.0.layer.LayerNorm.weight', 'item_encoder.blocks.0.layer.LayerNorm.bias', 'item_encoder.blocks.0.feed_forward.dense_1.weight', 'item_encoder.blocks.0.feed_forward.dense_1.bias', 'item_encoder.blocks.0.feed_forward.dense_2.weight', 'item_encoder.blocks.0.feed_forward.dense_2.bias', 'item_encoder.blocks.0.feed_forward.LayerNorm.weight', 'item_encoder.blocks.0.feed_forward.LayerNorm.bias', 'item_encoder.blocks.1.layer.query.weight', 'item_encoder.blocks.1.layer.query.bias', 'item_encoder.blocks.1.layer.key.weight', 'item_encoder.blocks.1.layer.key.bias', 'item_encoder.blocks.1.layer.value.weight', 'item_encoder.blocks.1.layer.value.bias', 'item_encoder.blocks.1.layer.dense.weight', 'item_encoder.blocks.1.layer.dense.bias', 'item_encoder.blocks.1.layer.LayerNorm.weight', 'item_encoder.blocks.1.layer.LayerNorm.bias', 'item_encoder.blocks.1.feed_forward.dense_1.weight', 'item_encoder.blocks.1.feed_forward.dense_1.bias', 'item_encoder.blocks.1.feed_forward.dense_2.weight', 'item_encoder.blocks.1.feed_forward.dense_2.bias', 'item_encoder.blocks.1.feed_forward.LayerNorm.weight', 'item_encoder.blocks.1.feed_forward.LayerNorm.bias'])
2025-06-23 12:56:21,449 - Load model from output/DuoRec_Diginetica.pt for test!
2025-06-23 12:56:26,030 - {'Epoch': 0, 'HR@5': '0.1532', 'NDCG@5': '0.1002', 'HR@10': '0.2279', 'NDCG@10': '0.1243', 'HR@20': '0.3228', 'NDCG@20': '0.1482'}
2025-06-23 12:56:26,304 - Saved predictions in `output/predictions/DuoRec_Diginetica_predictions.csv`
2025-06-23 12:56:26,305 - Jun-23-2025_12-56-17
2025-06-23 12:56:26,305 - {'Epoch': 0, 'HR@5': '0.1532', 'NDCG@5': '0.1002', 'HR@10': '0.2279', 'NDCG@10': '0.1243', 'HR@20': '0.3228', 'NDCG@20': '0.1482'}
